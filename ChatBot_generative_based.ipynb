{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Asmit Shrestha\n",
    "\n",
    "Roll: 1928433\n",
    "\n",
    "project name: Generative chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1) Importing the packages**\n",
    "\n",
    "\n",
    "Importing TensorFlow and Keras. Also,imported other modules which help in defining model layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, activations, models, preprocessing\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras import preprocessing, utils\n",
    "from keras.regularizers import l1\n",
    "import os, sys\n",
    "import yaml\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Preprocessing the data**\n",
    "\n",
    "**A) Downloading the dataset**\n",
    "\n",
    "The dataset is downloaded from https://www.kaggle.com/kausr25/chatterbotenglishchatterbot/english on Kaggle.com. It contains pairs of questions and answers based on a number of subjects like food, history, AI etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B) Reading the data from the files**\n",
    "\n",
    "Here I parse each of the .yaml files.\n",
    "\n",
    "-Concatenate two or more sentences if the answer has two or more of them.\n",
    "\n",
    "-Remove unwanted data types which are produced while parsing the data.\n",
    "\n",
    "-Append <START> and <END> to all the answers.\n",
    "    \n",
    "-Create a Tokenizer and load the whole vocabulary ( questions + answers ) into it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = r'data'\n",
    "files_list = os.listdir(dir_path + os.sep)\n",
    "\n",
    "questions = list()\n",
    "answers = list()\n",
    "\n",
    "for filepath in files_list:\n",
    "    stream = open( dir_path + os.sep + filepath , 'rb')\n",
    "    docs = yaml.safe_load(stream)\n",
    "    conversations = docs['conversations']\n",
    "    for con in conversations:\n",
    "        if len( con ) > 2 :\n",
    "            questions.append(con[0])\n",
    "            replies = con[ 1 : ]\n",
    "            ans = ''\n",
    "            for rep in replies:\n",
    "                ans += ' ' + rep\n",
    "            answers.append( ans )\n",
    "        elif len( con )> 1:\n",
    "            questions.append(con[0])\n",
    "            answers.append(con[1])\n",
    "\n",
    "answers_with_tags = list()\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "\n",
    "answers = list()\n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VOCAB SIZE : 2456\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'VOCAB SIZE : {}'.format( VOCAB_SIZE ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "    vocab.append( word )\n",
    "\n",
    "def tokenize( sentences ):\n",
    "    tokens_list = []\n",
    "    vocabulary = []\n",
    "    for sentence in sentences:\n",
    "        sentence = str(sentence).lower()\n",
    "        sentence = re.sub( '[^a-zA-Z]', ' ', sentence )\n",
    "        result = sentence.translate(str.maketrans(\"\",\"\", string.punctuation))\n",
    "        tokens = result.split()\n",
    "        vocabulary += tokens\n",
    "        tokens_list.append( tokens )\n",
    "    return tokens_list , vocabulary\n",
    "\n",
    "p = tokenize( questions + answers )\n",
    "len(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C) Preparing data for Seq2Seq model**\n",
    "\n",
    "\n",
    "\n",
    "This model requires three arrays namely e_input, d_input and d_output.\n",
    "\n",
    "For e_input :\n",
    "- Tokenize the questions. Pad them to their maximum length.\n",
    "\n",
    "For d_input :\n",
    "- Tokenize the answers. Pad them to their maximum length.\n",
    "\n",
    "For d_output :\n",
    "- Tokenize the answers. Remove the first element from all the tokenized_answers. This is the <START> element which we added earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# e_input\n",
    "tokenized_questions = tokenizer.texts_to_sequences(questions)  # Transform each question in a sequence of integers.\n",
    "maxlen_questions = max([len(x) for x in tokenized_questions])  # question with maximum length i.e is 50\n",
    "padded_questions = preprocessing.sequence.pad_sequences(tokenized_questions, maxlen=maxlen_questions,\n",
    "                                                            padding='post') \n",
    "# ensure that all sequences in a list have the same length\n",
    "e_input = np.array(padded_questions)  # create array\n",
    "\n",
    "    # d_input\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)  # Transform each text in texts in a sequence of integers.\n",
    "maxlen_answers = max([len(x) for x in tokenized_answers])  # answer with maximum length i.e is 74\n",
    "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers,\n",
    "                                                          padding='post')  \n",
    "# ensure that all sequences in a list have the same length\n",
    "d_input = np.array(padded_answers)  # create array\n",
    "\n",
    "# d_output: Tokenize the answers. Remove the first element from all the tokenized_answers.\n",
    "# This is the <START> element which we added earlier.\n",
    "tokenized_answers = tokenizer.texts_to_sequences(answers)  # Transform each text in texts in a sequence of integers.\n",
    "for i in range(len(tokenized_answers)):\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]  # remove first element form all the tokenized_answers.\n",
    "\n",
    "padded_answers = preprocessing.sequence.pad_sequences(tokenized_answers, maxlen=maxlen_answers,\n",
    "                                                          padding='post')  \n",
    "# ensure that all sequences in a list have the same length\n",
    "onehot_answers = utils.to_categorical(padded_answers,\n",
    "                                          VOCAB_SIZE)  # Converts a class vector (integers) to binary class matrix.\n",
    "d_output = np.array(onehot_answers)  # create array of onehot_answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Defining the Encoder-Decoder model\n",
    "\n",
    "The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n",
    "\n",
    "- 2 Input Layers : One for e_input and another for d_input.\n",
    "\n",
    "- Embedding layer : For converting token vectors to fix sized dense vectors. \n",
    "\n",
    "- LSTM layer : Provide access to Long-Short Term cells.\n",
    "\n",
    "Working :\n",
    "\n",
    "- The e_input comes in the Embedding layer ( encoder_embedding ).\n",
    "\n",
    "- The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( h and c which are encoder_states )\n",
    "\n",
    "- These states are set in the LSTM cell of the decoder.\n",
    "\n",
    "- The d_input comes in through the Embedding layer.\n",
    "\n",
    "- The Embeddings goes in LSTM cell ( which had the states ) to produce seqeunces.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.keras.layers.Input(shape=(None,))  # Input() is used to instantiate a Keras tensor\n",
    "encoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 300, mask_zero=True)(encoder_inputs)  \n",
    "# Turns positive integers (indexes) into dense vectors of fixed size\n",
    "encoder_outputs, state_h, state_c = tf.keras.layers.LSTM(300, return_state=True)(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=(None,))\n",
    "decoder_embedding = tf.keras.layers.Embedding(VOCAB_SIZE, 300, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM(300,activity_regularizer=l1(0.001), return_state=True, return_sequences=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = tf.keras.layers.Dense(VOCAB_SIZE, activation=tf.keras.activations.softmax)\n",
    "output = decoder_dense(decoder_outputs)\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**categorical_crossentropy**\n",
    "\n",
    "Categorical crossentropy is a loss function that is used for single label categorization. This is when only one category is applicable for each data point. In other words, an example can belong to one class only. \n",
    "\n",
    "The block before the Target block must use the activation function ​Softmax.\n",
    "\n",
    "**Regularizers**\n",
    "\n",
    "Regularizers allow to apply penalties on layer parameters or layer activity during optimization. These penalties are incorporated in the loss function that the network optimizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, None, 300)    735900      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 300)    735900      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 300), (None, 721200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 300),  721200      embedding_1[0][0]                \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2453)   738353      lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,652,553\n",
      "Trainable params: 3,652,553\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"model/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "    # Create a callback that saves the model's weights\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
    "                                                     save_weights_only=True\n",
    "                                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Training the model\n",
    "\n",
    "I train the model for a 40 epochs with RMSprop optimizer and categorical_crossentropy loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 891 samples\n",
      "Epoch 1/40\n",
      "891/891 [==============================] - 13s 15ms/sample - loss: 1.3628 - accuracy: 0.0244\n",
      "Epoch 2/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 1.2133 - accuracy: 0.0646\n",
      "Epoch 3/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 1.0523 - accuracy: 0.1056\n",
      "Epoch 4/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.9880 - accuracy: 0.1841\n",
      "Epoch 5/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.9380 - accuracy: 0.2101\n",
      "Epoch 6/40\n",
      "891/891 [==============================] - 6s 7ms/sample - loss: 0.8908 - accuracy: 0.2350\n",
      "Epoch 7/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.8475 - accuracy: 0.2674\n",
      "Epoch 8/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.8086 - accuracy: 0.2973\n",
      "Epoch 9/40\n",
      "891/891 [==============================] - 6s 7ms/sample - loss: 0.7727 - accuracy: 0.3189\n",
      "Epoch 10/40\n",
      "891/891 [==============================] - 11s 12ms/sample - loss: 0.7378 - accuracy: 0.3438\n",
      "Epoch 11/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.7023 - accuracy: 0.3688\n",
      "Epoch 12/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.6672 - accuracy: 0.3980\n",
      "Epoch 13/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.6331 - accuracy: 0.4326\n",
      "Epoch 14/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.5986 - accuracy: 0.4659\n",
      "Epoch 15/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.5674 - accuracy: 0.4988\n",
      "Epoch 16/40\n",
      "891/891 [==============================] - 6s 7ms/sample - loss: 0.5368 - accuracy: 0.5252\n",
      "Epoch 17/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.5069 - accuracy: 0.5584\n",
      "Epoch 18/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.4784 - accuracy: 0.5908\n",
      "Epoch 19/40\n",
      "891/891 [==============================] - 6s 7ms/sample - loss: 0.4520 - accuracy: 0.6228\n",
      "Epoch 20/40\n",
      "891/891 [==============================] - 10s 11ms/sample - loss: 0.4259 - accuracy: 0.6529\n",
      "Epoch 21/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.4010 - accuracy: 0.6885\n",
      "Epoch 22/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.3785 - accuracy: 0.7197\n",
      "Epoch 23/40\n",
      "891/891 [==============================] - 6s 7ms/sample - loss: 0.3560 - accuracy: 0.7496\n",
      "Epoch 24/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.3353 - accuracy: 0.7810\n",
      "Epoch 25/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.3160 - accuracy: 0.8075\n",
      "Epoch 26/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.2986 - accuracy: 0.8277\n",
      "Epoch 27/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.2814 - accuracy: 0.8521\n",
      "Epoch 28/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.2663 - accuracy: 0.8676\n",
      "Epoch 29/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.2514 - accuracy: 0.8858\n",
      "Epoch 30/40\n",
      "891/891 [==============================] - 10s 11ms/sample - loss: 0.2389 - accuracy: 0.9018\n",
      "Epoch 31/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.2268 - accuracy: 0.9154\n",
      "Epoch 32/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.2153 - accuracy: 0.9296\n",
      "Epoch 33/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.2055 - accuracy: 0.9382\n",
      "Epoch 34/40\n",
      "891/891 [==============================] - 6s 6ms/sample - loss: 0.1965 - accuracy: 0.9434\n",
      "Epoch 35/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.1881 - accuracy: 0.9529\n",
      "Epoch 36/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.1803 - accuracy: 0.9587\n",
      "Epoch 37/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.1737 - accuracy: 0.9614\n",
      "Epoch 38/40\n",
      "891/891 [==============================] - 5s 6ms/sample - loss: 0.1673 - accuracy: 0.9661\n",
      "Epoch 39/40\n",
      "891/891 [==============================] - 7s 8ms/sample - loss: 0.1619 - accuracy: 0.9667\n",
      "Epoch 40/40\n",
      "891/891 [==============================] - 7s 7ms/sample - loss: 0.1556 - accuracy: 0.9707\n"
     ]
    }
   ],
   "source": [
    "history=model.fit([e_input, d_input], d_output, batch_size=64, epochs=40, callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3iV9fnH8fedEJaAzCJ7D0GZYYPIUpClDBUVRVDK8idqLWpbbdVWcLSWAgIiToZQQAEZMkSQHZC9N2GGISSsQHL//vgeSoxJCJCT5yTnfl3Xuc56cvLJo+TO852iqhhjjAleIV4HMMYY4y0rBMYYE+SsEBhjTJCzQmCMMUHOCoExxgS5LF4HuFEFCxbU0qVLex3DGGMylDVr1pxQ1UJJvZfhCkHp0qWJiIjwOoYxxmQoIrI/uff81jQkImNF5LiIbLrOcXVEJE5EuvgrizHGmOT5s4/gM6B1SgeISCgwBJjrxxzGGGNS4LdCoKqLgVPXOew5YApw3F85jDHGpMyzUUMiUgx4CBiZimN7i0iEiERERUX5P5wxxgQRL4ePfggMUtW46x2oqqNVNVxVwwsVSrLT2xhjzE3yctRQODBRRAAKAg+IyBVV/cbDTMYYE3Q8KwSqWubqYxH5DJhpRcAYY9KfP4ePTgCWA5VEJFJEeolIHxHp46/vmaKtW+GFFyA21pNvb4wxgcpvVwSq2u0Gju3hrxz/s3cvfPghNGsGHTr4/dsZY0xGETxrDbVqBQULwvjxXicxxpiAEjyFICwMHn4Ypk+H6Giv0xhjTMAInkIA8NhjcOECfGN90sYYc1VwFYKGDaF0aWseMsaYBIKrEIhAt24wbx4ct1UtjDEGgq0QADz+OMTFwaRJXicxxpiAEHyFoGpVqFYNxo3zOokxxgSE4CsE4DqNV6yAPXu8TmKMMZ4LzkLQzTfXzTqNjTEmSAtByZLQpIlrHlL1Oo0xxngqOAsBuE7jbdtg3TqvkxhjjKeCtxB06QJZsljzkDEm6AVvIShQANq0gQkT3HBSY4wJUsFbCMCNHjp0CJYs8TqJMcZ4JrgLQYcOcNttNqfAGBPUgrsQ5MwJDz0E//0vXLrkdRpjjPFEcBcCcM1Dv/wCs2d7ncQYYzxhhaBlSyhUyEYPGWOClhWCqxvWzJgBZ896ncYYY9KdFQJwk8suXoRp07xOYowx6c5vhUBExorIcRHZlMz7j4vIBt9tmYhU91eW66pfH8qUseYhY0xQ8ucVwWdA6xTe3ws0VdVqwFvAaD9mSdnVDWvmz4eoKM9iGGOMF/xWCFR1MXAqhfeXqepp39MVQHF/ZUmVrl0hPt72MzbGBJ1A6SPoBSQ7flNEeotIhIhERPnrL/bq1aFcOTenwBhjgojnhUBEmuEKwaDkjlHV0aoarqrhhQoV8lcQtxDdggVw8qR/vocxxgQgTwuBiFQDxgAdVdX7375durgF6KZP9zqJMcakG88KgYiUBKYC3VV1h1c5fqV2bShVypqHjDFBJYu/PlhEJgD3AgVFJBJ4AwgDUNWRwOtAAWCEiABcUdVwf+VJlavNQ0OHumUn8ub1NI4xxqQH0Qy2VWN4eLhGRET47xusWAENGsAXX0D37v77PsYYk45EZE1yf2x73lkccOrWheLFrXnIGBM0rBAkFhICnTvD3Lm29pAxJihYIUhKly5uf4LvvvM6iTHG+J0VgqQ0bAhFiljzkDEmKFghSEpICHTqBLNmQUyM12mMMcavrBAkp0sXtzS17VxmjMnkrBAkp0kTt3OZNQ8ZYzI5KwTJCQ11zUPffQfnz3udxhhj/MYKQUq6dIFz59xQUmOMyaSsEKSkaVMoUMCah4wxmZoVgpSEhcGDD7qN7S9e9DqNMcb4hRWC6+nSBaKjYd48r5MYY4xfWCG4nubN3Sqk1jxkjMmkrBBcT9as0LEjfPstxMZ6ncYYY9KcFYLU6NIFzpxx21gaY0wmY4UgNVq1gty5YcIEr5MYY0yas0KQGtmyQY8e8OWXMHWq12mMMSZNWSFIrXffhXr13K5l69d7ncYYY9KMFYLUyp4dpk2DfPmgQwc4ftzrRMYYkyasENyIIkXgm29cEejSxUYRGWMyBSsENyo8HMaOhSVLoH9/UPU6kTHG3BK/FQIRGSsix0VkUzLvi4gMFZFdIrJBRGr5K0ua69YNXn0VxoyB4cO9TmOMMbfEn1cEnwGtU3i/DVDBd+sNfOTHLGnv7behfXsYONDmFxhjMjS/FQJVXQycSuGQjsAX6qwA8opIEX/lSXMhITBuHFSuDF27wq5dXicyxpib4mUfQTHgYILnkb7XfkNEeotIhIhEREVFpUu4VMmdG6ZPBxE3kujMGa8TGWPMDfOyEEgSryXZ86qqo1U1XFXDCxUq5OdYN6hsWbcg3Y4drqno7FmvExljzA3xshBEAiUSPC8OHPYoy61p1gzGj4fly6FFCzh50utExhiTalk8/N7TgQEiMhGoB5xR1SMe5rk1Dz8Mt90GnTu7nc3mzXPzDowxJhVUlXOXz3Hy/ElOXjjJifMnfvO4RdkWPFj5wTT/3n4rBCIyAbgXKCgikcAbQBiAqo4EZgEPALuA88DT/sqSbtq2hdmzXRNRkyZuNFGpUl6nMsb4SWxcLNGXoomOjSYmNoYzF89w7NwxjsUc4/i54+5xgue/XPyFOI0jLj7uV/dX4q8Qr/Epfq+82fNSOFdhvxQC0Qw2ISo8PFwjIiK8jpGyFSugTRvIlQvmz4dKlbxOZIxJBVXl7KWzRJ6N/O0tOpJDZw9x9tJZomOjib4UzeX4yyl+XoEcBSicqzCFbytM4VyFyZstL1lCshAaEkqohP7m/rast1EwZ0EK5ChAgZwF/vc4X458ZAm5tb/bRWSNqoYn9Z6XTUOZV/368OOPbvnqJk1cM1H16l6nMsYkEBMbw6bjm9hwbMP/bhuPb+SXi7/86jhBKJyrMMXzFKdMvjLkzZ6X3FlzkztrbnJlzUXubNce58mW53+/+AvmLEhYaJhHP92NsULgL9WqweLF0LIl3HuvazKqX9/rVMYEjQuXL3Ak5ghHoo9wOPowR2Lc/Y6TO9hwbAO7T+/+37G5s+amWuFqPFr1UcrlL0fxPMUpnqc4JfKUoEjuImQNzerhT+J/Vgj8qVIl+OknVwxatnQL1rVs6XUqYzKN6EvRbD2xla1RW9kStYUtJ7aw5/QeDkcf/s1f9gBhIWGUyVeGWkVq0aNGD6oVrka1wtUodXspRJIa0R4crBD4W6lSboG6++93/QaffQaPP+51KmMynNMXTrNw70J+OvATW05sYWvUVg6evTYnNWtoVioWqEilApVoVroZRXMXpUiuIu4+t7vPnyM/IWJrbSZmhSA93HGHayZ66CF44gk4dAheftnNSDbGJOnSlUssj1zOvN3zmLdnHmuOrCFe48mRJQdVClWhaemmVClYhTsL3UmVQlUom6/sLXeoBis7a+nl9ttdP0GPHjBokCsG//wnhIZ6ncyYgBCv8Ww8tpGFexcyb888ftz/I+cvnydUQqlXvB5/uecvtCrbirrF6maYTtiMwgpBesqWzS1UV7SoKwKHD7t9kLNn9zqZMelOVdlxcgcL9y5k4b6F/LD3B05ecLPyKxWoRM8aPWlVrhVNSzXl9uy3e5w2c7NCkN5CQuCDD6BYMXjpJbfb2TffuC0wjcnkjsUcY9bOWSzYu4CFexdyJMYtJlAiTwnaV2pPs9LNaFa6GSVuL3GdTzJpyQqBV1580V0ZPPmkm2swezaUsP/5TeaiqmyO2sz07dOZsWMGKyNXoiiFbytM8zLNaV6mOc1KN6NsvrJBPWrHa1YIvPToo/C737lO5AYNYMYMqFnT61TG3JLYuFgW71/MjO0zmL5jOvt+2QdAnaJ1+Nu9f6N9pfZUL1zdfvEHECsEXmve3I0oat8eGjd2w0u7dvU6lTE3JC4+jkX7FjFh0wSmbp3K6YunyZ4lOy3LtuTVxq/SrmI7iuYu6nVMkwwrBIGgenVYvRo6dXKrmL7+OrzxhutPMCZAxWs8yw8uZ+KmiUzeMplj546RK2suHqz8IJ3v7Eyrsq24LettXsc0qWCFIFAULgwLF0LfvvDmm7BxI3zxhVu4zpgAERcfx+rDq5m6dSpfb/6aA2cOkD1LdtpWaMujdz1K2wptyRGWw+uY5gZZIQgk2bLBJ5+4K4QXX4SGDd1WmKVLe53MBLEzF8/w/e7vmblzJrN3zibqfBRZQrJwf7n7+Xvzv9OhUgfyZMvjdUxzC6wQBBoReP55uPNOeOQRqFPHbYXZtKnXyUwQ2X5iOzN3zGTmzpn8dOAnrsRfIX+O/LQu35q2FdrSunxr8ufI73VMk0asEASq++6DlSuhQwe3UN1//gO//70tS2H8Jl7jmbF9Bu8te4+lB5cCcPfv7uYPDf5Au4rtqFe8ni3hkEnZf9VAVrGiKwbdurm+g8WLYeRIyGOX4SbtXLpyia82fMV7y95j+8ntlM5bmn/d/y863dmJkreX9DqeSQdWCALd7be7+QWDB7uRRKtWwcSJEJ7kRkPGpNovF39hVMQoPlz5IUdjjlLzjppM6DyBLlW62F/+Qcb+a2cEoaHwpz+5DW66dXOdyIMHw8CBNsTU3LCdJ3cyas0oRq8ZTXRsNK3KtuLLh76kRZkWNskrSF23EIhIO2CW6nV2Vjb+16gRrFsHvXq5dYoWLHAT0AoV8jqZCXDnYs8xectkxv48liUHlhAqoTxc9WFebvgyNYvYbPZgl5o/Jx8FdorIuyJy5418uIi0FpHtIrJLRF5J4v3bRWSGiKwXkc0i8vSNfH5Qyp8fpk6FYcNg/nyoUQMWLfI6lQlAqsryg8t5dvqz3PHBHTz97dMcjTnKOy3e4cALBxjfebwVAQOAqOr1DxLJA3QDngYU+BSYoKrRKXxNKLADaAVEAquBbqq6JcExrwG3q+ogESkEbAfuUNXY5D43PDxcIyIiUvOzZX7r1rkhpjt3uqaj11+HMFunPdjFxMYwes1oPl77MdtObCNnWE4ervowvWr2olGJRtb8E6REZI2qJtm5mKoGZlU9C0wBJgJFgIeAtSLyXApfVhfYpap7fL/YJwIdE380kFvc/5m5gFPAldRkMrirgTVr4Kmn4O23oV492LTJ61TGIzGxMby79F3K/LsML33/Evmy52NM+zEcfekon3b8lMYlG1sRMEm6biEQkfYiMg1YCIQBdVW1DVAd+EMKX1oMOJjgeaTvtYSGAXcCh4GNwPNJ9UWISG8RiRCRiKioqOtFDi65csGnn8K0aW7Xs9q14d13IS7O62QmnSQsAIPmDyK8aDjLey1nWa9l9KrVi9zZcnsd0QS41FwRdAX+parVVPU9VT0OoKrngZ4pfF1Sf3okboe6H1gHFAVqAMN8zVC//iLV0aoarqrhhaxjNGkPPuiuBtq1c1thNmnimoxMppVcAZj9+GzqF6/vdTyTgaSmELwBrLr6RERyiEhpAFVdkMLXRQIJd1opjvvLP6Gnganq7AL2ApVTkckkpVAhtxzFuHGwdatbs2jYMIi3AV+ZSWxcLB8s+8AKgEkzqSkEk4GEv0nifK9dz2qggoiUEZGsuNFH0xMdcwBoASAihYFKwJ5UfLZJjgg89pi7OmjaFJ57zi1XsX+/18lMGpi3ex7VPqrGH+b9gdpFalsBMGkiNYUgS8JRPL7HWa/3Rap6BRgAzAW2ApNUdbOI9BGRPr7D3gIaishGYAEwSFVP3OgPYZJQrBjMmgWjR7tlKu66yy1PYVcHGdL+X/bTeVJn7vvqPuI0ju8e+445T8yxAmDSxHWHj4rIPOA/qjrd97wj8H+q2iId8v2GDR+9Cfv2wbPPunkHzZrBmDFQtqzXqUwqXLxykfeWvsc7P72DiPDnJn/mxQYvki1LNq+jmQzmVoeP9gFeE5EDInIQGAT8Pi0DGj8rXRq+/x4+/tgNN737bhg61K4OAtyM7TOoOqIqry96nXYV27G1/1ZebfKqFQGT5q5bCFR1t6rWB6oAVVS1oa9j12QkIvDMM9f6Dp5/3t3v2OF1MpPI1qitPDDuATpM7EC20GzM7z6fSV0n2Uqgxm9SteiciLQFqgLZr05IUdU3/ZjL+EuJEvDdd24bzIED3ciit96CF15wi9sZz5w4f4K/LvorIyNGkitrLj647wOeq/scYaE2W9z4V2omlI0EHgGew80N6AqU8nMu408ibjbyli1w//3w8svQuDFs3+51sqAUGxfLP5f/k/JDyzMyYiS/r/17dj63kxcbvGhFwKSL1PQRNFTVJ4HTqvo3oAG/nh9gMqoiRdyM5HHjXBGoUQP+9S+blZxOVJVvtn1D1RFVeen7l2hQogEb+m5geNvhFLrNJk6a9JOaQnDRd39eRIoCl4Ey/otk0tXVeQebN7stMV980e17sMu6gfxpw7ENNP+iOQ99/RBhIWHMfnw2sx+fTZVCVbyOZoJQagrBDBHJC7wHrAX2ARP8Gcp4oEgRmD7d7W+wcaPNSvaTUxdOMWDWAGqOqsnGYxsZ1mYYG/puoHX51l5HM0EsxXkEIhIC1FfVZb7n2YDsqnomnfL9hs0jSAeRkW6E0dy57upg7FgoYxeBtyIuPo6xP4/l1QWvcvriafqG9+XNZm+SP0d+r6OZIHHT8wh8K4F+kOD5JS+LgEknxYvD7Nm/nnfw0Ud2dXCTVkSuoN6YevSe2Zsqhaqwtvdahj0wzIqACRipaRr6XkQ6iy1kHlyuzjvYuBHq14d+/aBVK9i71+tkGcbRmKP0+KYHDT5pwJGYI4zrNI4fe/xI9Tuqex3NmF9JTSF4EbfI3CUROSsi0SJy1s+5TKAoVQrmzYNRo2D1and1MGKEXR2kQFUZs3YMlYZVYvzG8QxqNIjtA7bz2N2P2cYwJiClZmZxblUNUdWsqprH9/w3ewaYTEwEevd2s5IbNoT+/aFFC9hjC8UmFnk2kjbj2vDsjGepXaQ2m/ptYnDLweTKmsvraMYk67ozi0XknqReV9XFaR/HBLSSJV0H8iefuGGmd98NQ4a4ZqOQVO16mmmpKp+v/5yBcwZyOf4yw9oMo2+dvoRIcJ8XkzGkZvXRGQmeZsftRbxGVZv7M1hybNRQgDh40F0lzJnj1iz6+GOoUMHrVJ44En2E3jN7M3PHTJqUbMKnHT+lXP5yXscy5lduafVRVW2f4NYKuAs4ltYhTQZTooTb7+CTT2DdOqhWzV0dXLnidbJ0o6qM2zCOqiOqMn/PfP51/79Y1GORFQGT4dzMdWskrhiYYCcCPXu6bTEfeABeeQXq1oWff/Y6md/t+2UfnSZ14olpT1C5YGXW91nPwPoDrSnIZEip6SP4D9c2nQ/BbTK/3p+hTAZTpAhMmeJuAwZAnTrwhz/AG29Ajhxep0tT0ZeiGfzTYD5Y/gEhEsK7Ld/lxQYvEhpiK7eajCs1y1AnbJC/AkxQ1aV+ymMyss6doXlzVwSGDIGpU13fQdOmXie7ZfEaz+frPue1ha9xNOYoT1R7gndavEPxPMW9jmbMLUvNdex/ga9U9XNVHQesEJGcfs5lMqp8+Vy/wfz5bhXTe++F3/8ezmTcCemL9y+mzsd16Dm9J6XzlmZFrxV8+dCXVgRMppGaQrAASHh9nwOY7584JtNo0cLNSn7pJbdHctWqbkOcDGTv6b10ndyVpp81JepcFOM7jWdZz2XUK17P62jGpKnUFILsqhpz9YnvsV0RmOvLmRPefx+WL4e8eaFdO3jiCTh50utkKbp45SJv/vgmVUZUYdbOWbx575tsG7CNbnd3s5nBJlNKTSE4JyK1rj4RkdrAhdR8uIi0FpHtIrJLRF5J5ph7RWSdiGwWkR9TF9tkKHXrusXrXn8dvv4aqlSByZPhOnNYvDBn1xzuGnEXbyx6gw6VOrB9wHb+0vQv5Ayzv31M5pWaQjAQmCwiS0RkCfA1MOB6XyQiocBwoA1u4/tuIlIl0TF5gRFAB1WtitsG02RG2bLB3/4GERFuDsLDD7vO5SNHvE4GwMEzB+k8qTNtxrUhNCSUed3n8XWXr60fwASF1EwoWw1UBvoC/YA7VXVNKj67LrBLVfeoaiwwEeiY6JjHgKmqesD3vY7fSHiTAVWvDitWwODBbkJalSpuZJFHi9jFxsUy5KchVB5emdk7Z/P35n9nQ58NtCzb0pM8xnghNZvX9wduU9VNqroRyCUi/VLx2cWAgwmeR/peS6gikE9EFonIGhF5MpkMvUUkQkQioqKiUvGtTUDLkgUGDYL16916Rb17u6WuV61K1xiL9i2ixsgavLLgFVqVbcWW/lt4rclrZMuSLV1zGOO11DQNPauqv1x9oqqngWdT8XVJ9aolbhTOAtQG2gL3A38RkYq/+SLV0aoarqrhhQrZpt6ZRqVK8OOP8OWXbu2ievWgVy847t8Lw2Mxx+g+rTvNPm/GxSsXmdFtBt88+g2l85b26/c1JlClphCEJNyUxtf2nzUVXxcJlEjwvDhwOIlj5qjqOVU9ASwGbNeOYCLiRhJt3+4mon3xBVSsCEOHpvm6RXHxcXy0+iMqD6/M15u+5k9N/sSmfptoV7Fdmn4fYzKa1BSCucAkEWkhIs1xG9fPTsXXrQYqiEgZEckKPApMT3TMt0ATEcnim6RWD9ia+vgm08iTB957z809qFcPnn8eataERYvS5OPXHllLg08a0G9WP2oVqcXGvht5u/nbNhrIGFJXCAbhJpX1BfoDG/j1BLMkqeoV3Oiiubhf7pNUdbOI9BGRPr5jtgJzfJ+5Chijqptu5gcxmUTlym5p62nTICYGmjVzI4z277+pjztz8Qz/N/v/qPNxHQ6cOcC4TuOY330+lQpWSuPgxmRc192PAEBEauBG+DwC7AGmqOowP2dLku1HEEQuXHBXCYMHuzkHf/yj62TOef2/4lWVyVsmM3DOQI7GHKVfnX683fxt8mbPmw7BjQk8N7UfgYhUFJHXRWQrMAzfCCBVbeZVETBBJkcONwlt+3Z46CF4803XwTxxYoqT0fae3kvb8W155L+PUDR3UVY9u4phDwyzImBMMlJqGtoGtADaq2pjVf0PEJc+sYxJoEQJGD8eliyBQoWgWzdo0gTWrv3VYZfjLvPu0nepOqIqSw4s4cP7P2TlMysJL5rkH0HGGJ+UCkFn4Cjwg4h8LCItSHpIqDHpo3FjWL3aLWK3cyeEh8Mzz8DRo6yMXEn4x+EMmj+I+8rdx5Z+W3i+/vO2T4AxqZBsIVDVaar6CG5W8SLgBaCwiHwkIvelUz5jfi001M012LEDXnoJ/eILLpYtybc96nPuzAmmPTKNbx79hhK3l7j+ZxljgNQtMXFOVcepajvcXIB1QJILyBmTXmJz5WDUI+Vp/GJeZpe6zD8WwI7hoTz484WAXMzOmEB2QxusquopVR2lqs39FciYlMTGxTIqYhQV/lOBPt/1Ib5COYrPXwU//EBIwYLw2GPQsKFb+toYkyq207bJEBIXgCK5ijDn8Tks67mMOsXquJ3QVq+GTz91cw4aNnSdyvv2eR3dmIBnhcAEtOQKwPJey7m//P2/3igmNBR69HD9B6+/Dt9+6yaovfwynDrl2c9gTKCzQmAC1oztM6j4n4rXLwCJ5crl9j7Yvt1dFXzwAZQtC0OGuElqxphfsUJgAk7k2Ug6fd2JDhM7kDtbbmY/Pjt1BSCxEiVcU9H69W7o6SuvQIUKMHYsxNmUGGOuskJgAkZcfBxDVw7lzuF3MmfXHAa3GMza3mtpXb71re0VfPfdMHOmW8CuWDE3/LR6dZgxw0YYGYMVAhMg1hxeQ70x9Xh+zvM0LtmYTf02MajxIMJCw9LumzRt6nZHmzwZYmOhQwc3Q3nBAisIJqhZITCeir4UzcA5A6k7pi6Hog/xdZevmfXYLMrmK+ufbygCXbrA5s0wYoQbVdSyJdxzjxUEE7SsEBjPfLvtW6qMqMLQlUPpU7sPW/tv5eGqD99aM1BqhYVB376waxcMHw5797qC0KQJzJ9vBcEEFSsEJt0dOnuITl934sGvHyRf9nws67WM4W2He7M6aPbs0K8f7N7tCsK+fdCqlRUEE1SsEJh0Excfx/BVw7lz+J3M3jWbwS0Gs6b3GuoXr+91NMiWLemC0LgxzJ1rBcFkalYITLrYcGwDjcY2YsDsAdQvXp9Nff3QGZwWEheEgwehdWto0ABmzbKCYDIlKwTGry5cvsCr81+l9uja7D69m68e+oq5T8ylXP5yXkdL2dWCsGsXjBoFR49C27ZQpw5Mn24FwWQqVgiM3/y470eqjazG4KWD6V6tO9v6b+Pxao+nT2dwWsmaFXr3dvsffPIJnD4NHTtCrVowdSrEx3ud0JhbZoXApLnoS9H0+64f935+L/Eaz8InFzK241gK5CzgdbSbFxYGPXvCtm3w2WcQEwOdO0O1avDll3D5stcJjblpfi0EItJaRLaLyC4RSXYPAxGpIyJxItLFn3mM/83ZNYeqI6oyMmIkL9R/gQ19NtCsTDOvY6WdsDB46inYuhW++srNS3jySbd0xfDhtpaRyZD8VghEJBQYDrQBqgDdRKRKMscNAeb6K4vxv1MXTtHjmx60GdeGXFlzsbTnUv55/z+5LettXkfzjyxZ4PHH3TpG06dD0aIwYACULg3vvANnznid0JhU8+cVQV1gl6ruUdVYYCLQMYnjngOmAMf9mMX40bSt06g6oipfbfiKPzX5E2t/v5YGJRp4HSt9hIRA+/awdKlby6hmTXjtNShZEl59FQ4d8jqhMdflz0JQDDiY4Hmk77X/EZFiwEPAyJQ+SER6i0iEiERERUWleVBzc7ZEbaH9hPZ0mtSJO3LdwepnV/N287fJniW719HSn4hby2jOHFizBu6/3y17XaoUPPwwLFliI41MwPJnIUhqaEjifwkfAoNUNcU1gVV1tKqGq2p4oUKF0iyguTlHY47SZ2Yf7v7obhbvX8yQlkNY9cwqahap6XW0wFCrFkya5IaeDhwI8+a5tYxq1oQxY+D8ea8TGvMr/iwEkUCJBM+LA4cTHRMOTBSRfUAXYISIPOjHTOYWnIs9x1s/vkX5oeX55OdP6F+nP7ue28UfG/0x8CaGBYKyZSbZjwAAABJ7SURBVOH9913z0OjRbqjps89C8eJu17S9e71OaAwAon66XBWRLMAOoAVwCFgNPKaqm5M5/jNgpqr+N6XPDQ8P14iIiDROa1ISFx/H5+s/5y8//IXD0YfpdGcnBrcYTIUCFbyOlrGouiaiYcOuzUFo3x6eew5atHDNS8b4iYisUdXwpN7z2xWBql4BBuBGA20FJqnqZhHpIyJ9/PV9TdqJ13imbJlCzVE16TW9FyXylOCnp39iysNTrAjcDBHXRDRpklvL6LXXYPlyt6ZR1arw0UdufoIx6cxvVwT+YlcE/hcbF8u4DeMYsnQI209up3z+8vyj+T/oUqVLxpoVnBFcvOgKw9ChrpP59tvh6aehf38oX97rdCYT8eSKwGQ852LP8e8V/6bc0HL0nN6THGE5+LrL12zrv42uVbtaEfCH7NndhLTVq2HZMnjgAdd0VLGiezxtms1aNn5nVwSG0xdOM2zVMP698t+cvHCSe0rdw6uNX+X+cje4WbxJG4cPu4XuxoxxjwsXdrOZn3nGzWA25iakdEVghSCIHYk+wj+X/5ORa0YSExtDu4rteLXxqzQs0dDraAbgyhU3L2HMGJg5E+Li3FyFZ55x6xzlyOF1QpOBWCEwv7L71G7eXfoun63/jCvxV3ik6iO80vgVqhWu5nU0k5wjR+Dzz11R2L3b9SV06+aalerXtxFH5rqsEBgA1h9dz+Clg5m0eRJhIWE8XeNpXm70sv82ijdpLz4eFi92BWHqVLfIXfny0L07PPGEm7tgTBKsEAQxVWXJgSUMWTqEWTtnkTtrbvqG92Vg/YEUyV3E63jmVpw964rBF1+4dY5U3daa3bu7ZS3yerAHtAlYVgiC0JmLZ/hyw5eMjBjJ5qjNFMxZkIH1BtK/bn9vNok3/nXgAIwb54rCtm1uh7XWraFrV2jXzjUlmaBmhSCIrDm8hpERIxm/aTznL5+nTtE69Anvw6N3PUrOsJxexzP+purmI3z1Ffz3v255i6xZ4b77oEsX6NAB8uXzOqXxgBWCTO785fNM3DSRjyI+IuJwBDnDcvLYXY/RJ7wPtYvW9jqe8Up8PKxcCZMnu6Jw8KDbWKdlS1cUOnaEAhl41zhzQ6wQZFLxGs/n6z7nTwv/xJGYI1QtVJU+4X3oXq07t2e3pgCTgKqbtPbf/7rCsG8fhIZCs2auKDz4oJuvYDItKwSZ0OL9i3lh7gusPbKWesXqMbjlYJqWamoTwMz1qcLatTBliisMO3e6DXaaNHHzEzp1gmLFrv85JkOxQpCJ7D61mz/O/yNTt06lRJ4SDGk5hEfvetQKgLk5qrBpkysIU6bAZt/iwPXrQ9u20KaN20chxFajyeisEGQCZy6e4e3FbzN01VDCQsJ4pfErvNTgJXKE2exSk4a2bXMF4Ztv4Oq/s9/9zo1AatPGdTrnz+9tRnNTrBBkYPEaz9ifx/Lagtc4cf4EPWr04O3mb1M0d1Gvo5nM7vhxmDsXZs9296dOuSuDevVcUWjTxu3GZlcLGYIVggxq/dH19P2uL8sjl9OkZBM+bP0htYrU8jqWCUZxcbBqlSsKs2dfu1ooWNDtz9y6tbu3rWQDlhWCDCb6UjRvLHqDoSuHkj9Hft6/7326V+tu/QAmcBw/Dt9/7xbFmzsXTpxw6x3Vru2KQsuWULeuLYwXQKwQZBCqypStUxg4ZyCHow/Tu3Zv/tHiH+TPYW2yJoDFx7tRSHPmuKuFFSvca2FhEB7uRiM1bgyNGln/goesEGQAu0/tZsDsAczZNYcad9Tgo7YfUb94fa9jGXPjTp+GpUvd/sw//eTmL1zdXKdqVVcYGjWChg2hTBlbOTWdWCEIYAfOHOD9Ze/z8dqPCQsJ461mb9G/bn+yhGTxOpoxaePCBVcMrhaGZcvcgnkAd9xxrSg0auSGqmbN6m3eTCqlQmC/bTyyJWoLQ5YOYfzG8QB0r9bdRgOZzClHDrjnHncD1/G8aZMrCEuXuvspU9x72bNDnTrQoIEbnVS/PhS1fxP+ZlcE6Wxl5Ere+ekdvt3+LTnDctK7Vm9ebPAiJW4v4XU0Y7xz+LArCFeLw88/X2tOKlHiWlGoX98NWbVO6BvmWdOQiLQG/g2EAmNUdXCi9x8HBvmexgB9VXV9Sp+ZEQuBqjJvzzze+ekdFu1bRL7s+Xiu7nM8V+85CuYs6HU8YwLPxYuwbp3reF650t3v2+feCw2FypWhenWoUcPdV69uayVdhyeFQERCgR1AKyASWA10U9UtCY5pCGxV1dMi0gb4q6rWS+lzM1IhUFVm7ZzFm4vfZNWhVRTNXZSXGrxE79q9yZU1l9fxjMlYjh51RWH1ali/3hWKyMhr799xx7WiULUq3HUX3HmnXT34eNVHUBfYpap7fCEmAh2B/xUCVV2W4PgVQHE/5kk38RrP9O3TeWvxW6w9spbSeUszqt0onqr+FNmyZPM6njEZ0x13uKWzO3a89trJk7BhgysK69e724cfQmyse18EypVzReFqcahSBSpWdP0RBvBvISgGHEzwPBJI6a/9XsDspN4Qkd5Ab4CSJUumVb40F6/xTNkyhbeXvM2GYxson788YzuM5YlqTxAWGuZ1PGMynwIF3FLazZpde+3KFdi1y3VIb9rkFtLbtAlmzHAd1eCWxShTxl0xJL4F4W5u/iwESQ0OTrIdSkSa4QpB46TeV9XRwGhwTUNpFTAtzdg+g1cWvMKWqC1UKlCJLx/6kkfvetSGgRqT3rJkcX0IlSu7vRauunTJLaq3deuvb99/f+0KAlxfQ8WKUKGCu796K1cu015F+PO3VCSQcChMceBw4oNEpBowBmijqif9mMdvVh9azYNfP0ilApWY0HkCXat0JTQk1OtYxpiEsmW71oeQ0JUrsHfvtcKwY4fbo+G772Ds2GvHibgRTGXLQunSv70VK+aKUAbkz87iLLjO4hbAIVxn8WOqujnBMSWBhcCTifoLkhVoncUXr1yk1qhaRMdGs6nvJtsZzJjM5OxZVxSuFocdO9zopX373JDXhL8/Q0OheHEoVSrpW8mSnl5ReNJZrKpXRGQAMBc3fHSsqm4WkT6+90cCrwMFgBG+BdWuJBc0UL3xwxtsPbGVuU/MtSJgTGaTJ49bSK92Ent/X7rk9oG+Whiu3vbvh0WL4NAht+ZSQr/7nZsgV6yYu0/4uFgxV0gKFEj3ZTdsQtktWH5wOY0/bcwzNZ9hVPtRXscxxgSSy5ddMdi//9rt4EF3JXH4sHvv+PHffl3OnO7qoWTJa1cSV+8rV77p+RK2xIQfnL98nqe+eYoSeUrw/n3vex3HGBNowsKu9R8kJzbWzY+4WhgiI13BOHDA3dat+3WxePllePfdNI9qheAm/Xnhn9l5aifzu88nd7bcXscxxmREWbNe++s/ORcuuCuJAwf8tu6SFYKbsGT/Ej5c8SH9wvvRomwLr+MYYzKzHDmuDWH1E9ts9Aadiz3H098+TZl8ZRjSaojXcYwx5pbZFcENemX+K+w+vZsfe/xo6wUZYzIFuyK4AT/s/YFhq4fxfL3nuafUPV7HMcaYNGGFIJWiL0XTc3pPyucvzz9a/MPrOMYYk2asaSgVLly+QM/pPdn/y36WPL2EnGE5vY5kjDFpxgrBdew5vYcuk7rw89GfebfluzQq2cjrSMYYk6asEKRg5o6ZdJ/W3T3uNpO2Fdt6nMgYY9Ke9REkIS4+jr8s/AvtJ7SnTN4yrO291oqAMSbTsiuCRKLORfHY1MeYv2c+PWv0ZNgDw8gRZlvdGWMyLysECayMXEnXyV05fu44Y9qPoVetXl5HMsYYv7OmIdwm8yNWj6DJp00IDQllac+lVgSMMUEj6K8Ioi9F03tmbyZumsgDFR7gy4e+JH+O/F7HMsaYdBPUhWDjsY10mdyFXad28Y/m/2BQ40GEiF0kGWOCS9AWgs/WfUa/7/pxe/bbWfDkAu4tfa/XkYwxxhNBVwguXL7AgFkDGLtuLM1KN2N85/HckesOr2MZY4xngqoQ7Di5g66Tu7Lh2Ab+3OTP/PXevxIaEup1LGOM8VTQFII5u+bw8OSHyRqaldmPz6Z1+dZeRzLGmIDg155REWktIttFZJeIvJLE+yIiQ33vbxCRWv7KUi5fORqWaMjPv//ZioAxxiTgtysCEQkFhgOtgEhgtYhMV9UtCQ5rA1Tw3eoBH/nu01yFAhWY88Qcf3y0McZkaP68IqgL7FLVPaoaC0wEOiY6piPwhTorgLwiUsSPmYwxxiTiz0JQDDiY4Hmk77UbPcYYY4wf+bMQSBKv6U0cg4j0FpEIEYmIiopKk3DGGGMcfxaCSKBEgufFgcM3cQyqOlpVw1U1vFChQmke1Bhjgpk/C8FqoIKIlBGRrMCjwPREx0wHnvSNHqoPnFHVI37MZIwxJhG/jRpS1SsiMgCYC4QCY1V1s4j08b0/EpgFPADsAs4DT/srjzHGmKT5dUKZqs7C/bJP+NrIBI8V6O/PDMYYY1JmS20aY0yQE/dHecYhIlHA/pv88oLAiTSMk5Ys280J5GwQ2Pks283JqNlKqWqSo20yXCG4FSISoarhXudIimW7OYGcDQI7n2W7OZkxmzUNGWNMkLNCYIwxQS7YCsForwOkwLLdnEDOBoGdz7LdnEyXLaj6CIwxxvxWsF0RGGOMScQKgTHGBLmgKQTX2y3NSyKyT0Q2isg6EYnwOMtYETkuIpsSvJZfROaJyE7ffb4AyvZXETnkO3frROQBj7KVEJEfRGSriGwWked9r3t+7lLI5vm5E5HsIrJKRNb7sv3N93ognLfksnl+3hJkDBWRn0Vkpu/5TZ23oOgj8O2WtoMEu6UB3RLtluYZEdkHhKuq55NUROQeIAa3YdBdvtfeBU6p6mBfEc2nqoMCJNtfgRhVfT+98yTKVgQooqprRSQ3sAZ4EOiBx+cuhWwP4/G5ExEBblPVGBEJA34Cngc64f15Sy5bawLg/zkAEXkRCAfyqGq7m/23GixXBKnZLc0AqroYOJXo5Y7A577Hn+N+iaS7ZLIFBFU9oqprfY+jga24TZY8P3cpZPOcb3fCGN/TMN9NCYzzlly2gCAixYG2wJgEL9/UeQuWQhDoO6Ep8L2IrBGR3l6HSULhq8uD++5/53GexAaIyAZf05EnzVYJiUhpoCawkgA7d4myQQCcO1/zxjrgODBPVQPmvCWTDQLgvAEfAn8E4hO8dlPnLVgKQap2QvNQI1WtBbQB+vuaQEzqfASUA2oAR4APvAwjIrmAKcBAVT3rZZbEksgWEOdOVeNUtQZuY6q6InKXFzmSkkw2z8+biLQDjqvqmrT4vGApBKnaCc0rqnrYd38cmIZrygokx3ztzFfbm497nOd/VPWY7x9rPPAxHp47XzvyFGCcqk71vRwQ5y6pbIF07nx5fgEW4drgA+K8XZUwW4Cct0ZAB1//4kSguYh8xU2et2ApBKnZLc0TInKbrwMPEbkNuA/YlPJXpbvpwFO+x08B33qY5Veu/k/v8xAenTtfx+InwFZV/WeCtzw/d8llC4RzJyKFRCSv73EOoCWwjcA4b0lmC4TzpqqvqmpxVS2N+322UFWf4GbPm6oGxQ23E9oOYDfwJ6/zJMhVFljvu232OhswAXe5exl3JdULKAAsAHb67vMHULYvgY3ABt8/giIeZWuMa27cAKzz3R4IhHOXQjbPzx1QDfjZl2ET8Lrv9UA4b8ll8/y8Jcp5LzDzVs5bUAwfNcYYk7xgaRoyxhiTDCsExhgT5KwQGGNMkLNCYIwxQc4KgTHGBDkrBMYkIiJxCVaWXCdpuFqtiJSWBKunGhMIsngdwJgAdEHdsgLGBAW7IjAmlcTtGzHEt0b9KhEp73u9lIgs8C1CtkBESvpeLywi03zr2a8XkYa+jwoVkY99a9x/75u1aoxnrBAY81s5EjUNPZLgvbOqWhcYhlv9Ed/jL1S1GjAOGOp7fSjwo6pWB2rhZo4DVACGq2pV4Begs59/HmNSZDOLjUlERGJUNVcSr+8DmqvqHt8ibkdVtYCInMAtM3DZ9/oRVS0oIlFAcVW9lOAzSuOWM67gez4ICFPVt/3/kxmTNLsiMObGaDKPkzsmKZcSPI7D+uqMx6wQGHNjHklwv9z3eBluBUiAx3FbGoJb9Ksv/G+DkzzpFdKYG2F/iRjzWzl8u1JdNUdVrw4hzSYiK3F/RHXzvfZ/wFgReRmIAp72vf48MFpEeuH+8u+LWz3VmIBifQTGpJKvjyBcVU94ncWYtGRNQ8YYE+TsisAYY4KcXREYY0yQs0JgjDFBzgqBMcYEOSsExhgT5KwQGGNMkPt/ixt75+cPtKAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "plt.plot(history.history['accuracy'],color='green')\n",
    "plt.plot(history.history['loss'],color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Defining inference models\n",
    "We create inference models which help in predicting answers.\n",
    "\n",
    "Encoder inference model : Takes the question as input and outputs LSTM states ( h and c ).\n",
    "\n",
    "Decoder inference model : Takes in 2 inputs, one are the LSTM states ( Output of encoder model ), second are the answer input seqeunces ( ones not having the <start> tag ). It will output the answers for the question which we fed to the encoder model and its state values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_inference_models():\n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "\n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=(300,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=(300,))\n",
    "\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "\n",
    "    return encoder_model, decoder_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Talking with our Chatbot\n",
    "\n",
    "First, we define a method str_to_tokens which converts str questions to Integer tokens with padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_to_tokens(sentence: str):\n",
    "    words = sentence.lower().split()\n",
    "    words = sentence.translate(str.maketrans(\"\", \"\", string.punctuation)).split()\n",
    "    tokens_list = list()\n",
    "\n",
    "    for word in words:\n",
    "        if word in vocab:\n",
    "            tokens_list.append(tokenizer.word_index[word])\n",
    "        elif word == \"quit\":\n",
    "            print(\"See ya!!\")\n",
    "\n",
    "        else:\n",
    "            return str_to_tokens(\"understand\")\n",
    "            # reply =  \"haha what??\"\n",
    "            # decoded_translation =\n",
    "            # decoded_translation = \"BOT :\" + ''\n",
    "            # #print(\"BOT : Can you eloborate the word {}.\".format(word))\n",
    "            break\n",
    "    return preprocessing.sequence.pad_sequences([tokens_list], maxlen=maxlen_questions, padding='post')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, it takes a question as input and predict the state values using enc_model.\n",
    "- Then, set the state values in the decoder's LSTM.\n",
    "- Then, we generate a sequence which contains the <start> element.\n",
    "- input this sequence in the dec_model.\n",
    "- replace the <start> element with the element which was predicted by the dec_model and update the state values.\n",
    "- carry out the above steps iteratively till we hit the <end> tag or the maximum answer length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter question : hy\n",
      "BOT :  what up bro end\n",
      "Enter question : how are you\n",
      "BOT :  i am doing well end\n",
      "Enter question : what are you doing\n",
      "BOT :  i was about to sleep wait i don't sleep never mind end\n",
      "Enter question : haha\n",
      "BOT :  the sort of active life hahha end\n",
      "Enter question : what up\n",
      "BOT :  my favorite subject is chemistry end\n",
      "Enter question : who are you\n",
      "BOT :  i am a bot end\n",
      "Enter question : good\n",
      "BOT :  you are a bad end\n",
      "Enter question : who built you\n",
      "BOT :  asmit shrestha end\n",
      "Enter question : wow\n",
      "BOT :  haha end\n",
      "Enter question : i am hungry\n",
      "BOT :  go and have some food end\n"
     ]
    }
   ],
   "source": [
    "enc_model, dec_model = make_inference_models()\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    states_values = enc_model.predict( str_to_tokens( input( 'Enter question : ' ) ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation ='BOT : '+ ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        \n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "            \n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "\n",
    "    print( decoded_translation )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
